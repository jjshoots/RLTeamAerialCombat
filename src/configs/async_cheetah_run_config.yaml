# env params
env:
  variant: "mlp_sa_env"
  id: "dm_control/cheetah-run-v0"
  num_envs: 4

# replay buffer params
replay_buffer:
  mem_size: 2000000
  mode: "torch"
  use_dict_wrapper: false
  store_on_device: true
  random_rollover: true

# algorithm params
algorithm:
  variant: "mlp"
  actor:
    variant: "simba"
    embed_dim: 256
    num_blocks: 1
  critic:
    variant: "simba"
    embed_dim: 256
    num_blocks: 2
  qu_num_ensemble: 2
  batch_size: 256
  grad_steps_per_update: 500
  actor_learning_rate: 0.001
  critic_learning_rate: 0.001
  alpha_learning_rate: 0.01
  target_smoothing_coefficient: 0.005
  tune_entropy: true
  target_entropy_gain: 1.0
  learn_uncertainty: true
  discount_factor: 0.99
  actor_update_ratio: 1
  critic_update_ratio: 1

# training config
runner:
  variant: "async"
  mode: "trainer"  # trainer, worker
  max_workers: 2

  trainer_settings:
    transitions_eval_frequency: 10000
    transitions_num_exploration: 25000
    transitions_min_for_train: 50000
    transitions_max: 5000000

  worker_settings:
    task: "null" # collect, eval
    collect_num_transitions: 8000
    eval_num_episodes: 16

# https://github.com/jjshoots/Wingman?tab=readme-ov-file#from-wingman-import-wingman
mode:
  debug: false
  train: false
  eval: false
  display: false
  render: false

model:
  save_directory: "weights"
  id: ""
  ckpt: 0
  increment_ckpt: false

logging:
  interval: 10
  max_skips: 5
  greater_than: 0.0
  filename: ""

wandb:
  enable: false
  save_code: false
  run:
    name: "half_cheetah"
    notes: ""
  project:
    name: "dogfighter"
    entity: "jjshoots"
