# env params
env:
  variant: "mlp_sa_env"
  id: "dm_control/cheetah-run-v0"
  num_envs: 8

# replay buffer params
replay_buffer:
  mem_size: 500000
  mode: "torch"
  use_dict_wrapper: false
  store_on_device: true
  random_rollover: true

# algorithm params
algorithm:
  variant: "mlp"
  actor:
    variant: "simba"
    embed_dim: 64
    num_blocks: 1
  critic:
    variant: "simba"
    embed_dim: 256
    num_blocks: 2
  qu_num_ensemble: 2
  batch_size: 4096
  grad_steps_per_update: 1000
  actor_learning_rate: 0.003
  critic_learning_rate: 0.003
  alpha_learning_rate: 0.01
  target_smoothing_coefficient: 0.005
  tune_entropy: true
  target_entropy_gain: 1.0
  learn_uncertainty: true
  discount_factor: 0.99
  actor_update_ratio: 1
  critic_update_ratio: 1

# training config
runner:
  variant: "async"
  mode: "trainer"  # trainer, worker
  num_parallel_workers: 2
  max_tasks_in_queue: 64

  transitions_eval_frequency: 8000
  transitions_num_exploration: 25000
  transitions_min_for_train: 50000
  transitions_max: 10000000

  trainer:
    steps_per_epoch: 1000
  worker:
    task: "null" # collect, eval
    actor_weights_path: ""
    result_output_path: "/dev/null"
    collect_num_transitions: 20000
    eval_num_episodes: 16

# https://github.com/jjshoots/Wingman?tab=readme-ov-file#from-wingman-import-wingman
mode:
  debug: false
  train: false
  eval: false
  display: false
  render: false

model:
  save_directory: "weights"
  id: ""
  ckpt: 0
  increment_ckpt: false

logging:
  interval: 10
  max_skips: 5
  greater_than: 0.0
  filename: ""

wandb:
  enable: false
  save_code: false
  run:
    name: "half_cheetah"
    notes: ""
  project:
    name: "dogfighter"
    entity: "jjshoots"
