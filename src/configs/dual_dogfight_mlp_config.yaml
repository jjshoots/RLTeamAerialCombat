# env params
env:
  name: "dogfight"
  variant: "mlp_ma_env"
  kwargs:
    team_size: 1
    flatten_observation: true

# replay buffer params
replay_buffer:
  mem_size: 1500000
  mode: "torch"
  use_dict_wrapper: false
  store_on_device: true
  random_rollover: true

# algorithm params
algorithm:
  variant: "mlp"
  actor:
    embed_dim: 64
    num_blocks: 1
  critic:
    embed_dim: 256
    num_blocks: 2
  qu_num_ensemble: 2
  batch_size: 2048
  grad_steps_per_update: 2000
  actor_learning_rate: 0.003
  critic_learning_rate: 0.003
  alpha_learning_rate: 0.01
  tune_entropy: true
  target_entropy_gain: 1.0
  learn_uncertainty: true
  discount_factor: 0.99
  actor_update_ratio: 1
  critic_update_ratio: 1

# training config
runner:
  max_transitions: 2500000
  transitions_per_epoch: 10000
  transitions_num_exploration: 10000
  train_min_transitions: 20000
  eval_num_episodes: 10
  eval_transitions_frequency: 10000

# wingman required params
# https://github.com/jjshoots/Wingman?tab=readme-ov-file#from-wingman-import-wingman
mode:
  debug: false
  train: false
  eval: false
  display: false
  render: false

model:
  save_directory: "weights"
  id: ""
  ckpt: 0
  increment_ckpt: false

logging:
  interval: 10
  max_skips: 5
  greater_than: 0.0
  filename: ""

wandb:
  enable: false
  save_code: false
  run:
    name: "1v1_dogfight_mlp"
    notes: ""
  project:
    name: "dogfighter"
    entity: "jjshoots"
